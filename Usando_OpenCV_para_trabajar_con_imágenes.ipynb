{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddMNV2Axm3BX"
      },
      "source": [
        "**NOTA**: Si detectas algún error en este Colab, pon un mensaje en el foro para que lo podamos solucionar o envía un correo.\n",
        "\n",
        "**NOTA**: Las imágenes utilizadas en este colab han sido descargadas de https://pixabay.com/es/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01uI3sE8vqTs"
      },
      "source": [
        "#  1 Extrayendo información "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDnqY8eWvz8I"
      },
      "source": [
        "Vamos a empezar revisando conceptos básicos de data mining y procesamiento de imágenes. Data mining es un proceso muy común en Data Science que consiste en descubrir información útil en un gran conjunto de datos. Procesamiento de imágenes hace referencia al proceso de mejorar o descubrir información útil en una imagen. Con estos dos conceptos, podemos hablar de minería de imágenes (o image mining) como el proceso de mejorar o descubrir información util de un gran dataset de imágenes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29KqOPJ2xG_3"
      },
      "source": [
        "**OpenCV** es una librería para **visión artificial** y **procesamiento de imágenes**. Ofrece soporte para varios lenguajes, pero en esta asignatura nos centraremos en Python. A continuación, revisaremos los conceptos fundamentales para utilizar OpenCV con Python. \n",
        "\n",
        "Lo primero que tenemos que hacer es instalar la librería de OpenCV. Como necesitaremos también Numpy y Matplotlib (esta última para algún ejemplo), las instalamos también si no las tenemos de colabs anteriores. A continuación tienes cómo instalar OpenCV para **Python 3.8**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "e-RYKIxbviWw",
        "outputId": "a9100c46-87de-4be9-a7cd-686682b4b331"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-bc151db59eb7>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    pip install opencv-python\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "rosenv\n",
        "\n",
        "pip install opencv-python\n",
        "pip install numpy\n",
        "pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_Ci8kBm8T_6"
      },
      "source": [
        "## 1.1 Operaciones de lectura/escritura"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wezG31477QLT"
      },
      "source": [
        "Las operaciones más básicas que podemos realizar con OpenCV son abrir una imagen, mostrarla y guardarla en un fichero. Estas opereaciones se pueden realizar con las siguientes funciones:\n",
        "\n",
        "* `imread`: cargar una imagen a partir de un fichero.\n",
        "* `imshow`: mostrar una imagen. Una vez tengo la imagen cargada (leída), puedo mostrarla. \n",
        "* `imwrite`: guardar una imagen en un fichero.\n",
        "\n",
        "En primer lugar, clona el siguiente repositorio que contiene las imágenes con las que trabajaremos en este colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AyjOTvLAHDes"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (Temp/ipykernel_45312/2059895143.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\dbs99\\AppData\\Local\\Temp/ipykernel_45312/2059895143.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    git clone https://gitlab.com/robotica_gti/opencv.git\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "git clone https://gitlab.com/robotica_gti/opencv.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEVEJJAHHFDb"
      },
      "source": [
        "Después, puedes crear el siguiente script que abre una imagen, la carga en una variable, la muestra y crea una nueva imagen como copia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PL_NjwN-kb1-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "#Cargamos una imagen\n",
        "img = cv2.imread(\"img/xiquet.jpg\")\n",
        "\n",
        "#Mostramos una imagen\n",
        "cv2.imshow(\"My Image\",img) #el primer parámetro es el nombre de la ventana, que puedo poner el que quiera\n",
        "cv2.waitKey(0) #aprieta una tecla \n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "#Escribimos en una imagen\n",
        "cv2.imwrite(\"image_copy.jpg\",img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYl6XZN6Pb_P"
      },
      "source": [
        "## 1.2 Datos básicos de las imágenes en OpenCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su6tuWjBzFBP"
      },
      "source": [
        "Una vez ya has visto cómo podemos leer y escribir una imagen, vamos a entender **cómo trabaja OpenCV** con las imágenes. Cuando cargamos una imagen con OpenCV, lo que hace es crear un **array de numpy** con 3 dimensiones, donde cada dimisión representa la siguiente información:\n",
        "* la coordenada vertical y \n",
        "* la coordenada horizonal x \n",
        "* el valor de color BGR del píxel (x,y)\n",
        "\n",
        "Hay que tener en cuenta que la coordenada (0,0) corresponde a la esquina superior izquierda de la imagen. A parte de los valores de cada píxel, también podemos obtener información general de cada imagen. Prueba a ejecutar el siguiente script:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gC9NEIo1lCom"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "#Cargamos una imagen\n",
        "img = cv2.imread(\"img/xiquet.jpg\")\n",
        "\n",
        "#Propiedades de la imagen\n",
        "print(type(img))\n",
        "print(img.shape) #píxeles verticales y horizontales\n",
        "print(img.size)\n",
        "print(img.dtype)\n",
        "\n",
        "top_left_px = img[0,0,:] #esto me devuelve una lista de 3 valores (BGR) del pixel 0,0\n",
        "print(top_left_px)\n",
        "\n",
        "top_left_px_R = img[0,0,2] #esto me devuelve solo la componente R\n",
        "print(top_left_px_R)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqLp_8dQgifD"
      },
      "source": [
        "## 1.3 Ejercicios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqwxJUQfgfXj"
      },
      "source": [
        "1. Realiza un script llamado **ejercicio1** que lea la imagen y cree una imagen nueva como la original convertida a escala de grises (**que el script muestre la imagen por pantalla**). Para la conversión, asigna a cada pixel un mismo valor a cada componente RGB utilizando la siguiente fórmula. Utiliza las funciones **np.sum** e **itemset** que ya vimos en el [colab de Numpy](https://colab.research.google.com/drive/1Hskb0vGEy3Dond5kJQXS_1X0KC7AI6KB?usp=sharing), si es posible.\n",
        "\n",
        "$$B' = G' = R' = \\frac{B+G+R}{3}$$\n",
        "\n",
        "2. Realiza un script llamado **ejercicio2** que lea una imagen y la rote 90º en el sentido horario, mostrando la nueva imagen por pantalla. La máxima nota se obtendrá si se realiza una copia píxel a píxel y no se utiliza la función del API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISuiHGng2Nno"
      },
      "source": [
        "Evidentemente, OpenCV nos ofrece muchas funcionalidades para manipular imágenes, de manera que no tenemos que implementarlas desde 0. Por ejemplo, si queremos convertir una imagen a **escala de grises** podemos utilizar la función **cvtColor**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOdVMo6U2plr"
      },
      "outputs": [],
      "source": [
        "#Cargamos una imagen\n",
        "img = cv2.imread(\"xiquet.jpg\")\n",
        "\n",
        "#Convertimos a escala de grises\n",
        "img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "cv2.imshow(\"My Image\",img_gray)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI1aDZlv3gjy"
      },
      "source": [
        "# 2 Escribiendo sobre imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKVhRFSA3x-Q"
      },
      "source": [
        "En ocasiones es interesante modificar una imagen añadiéndole algún elemento como un **texto**. Para ello, podemos utilizar la función **putText**, que recibe la imagen y el texto que queremos, y lo pone en unas coordenadas determinadas. A continuación, tienes un ejemplo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjPV1mpb3xjz"
      },
      "outputs": [],
      "source": [
        "#Cargamos una imagen\n",
        "img = cv2.imread(\"xiquet.jpg\")\n",
        "\n",
        "\n",
        "cv2.imshow(\"My Image\",img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMARCYa75BMh"
      },
      "source": [
        "A parte de poder escribir texto, OpenCV nos permite dibujar formas geométricas. Esto puede ser especialmente útil para el reconocimiento de objetos, ya que se suelen dibujar bounding boxes etiquetadas. En este sentido, OpenCV nos ofrece varias funciones como las siguientes:\n",
        "* **line** para dibujar líneas.\n",
        "* **rectange** para dibujar rectángulos.\n",
        "* **circle** para dibujar círculos.\n",
        "\n",
        "De forma similar a la anterior función, estas funciones reciben por parámetro la imagen, las coordenadas o el color. A continuación, tienes un ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWAonGhQ6HcV"
      },
      "outputs": [],
      "source": [
        "#Cargamos una imagen\n",
        "img = cv2.imread(\"xiquet.jpg\")\n",
        "\n",
        "#Definimos los parámetros que necesita la función rectangle()\n",
        "posicion_ini = (100,50)\n",
        "posicion_fin = (300,600)\n",
        "color = (0,0,255)\n",
        "\n",
        "cv2.rectangle(img,posicion_ini,posicion_fin,color,4)\n",
        "\n",
        "cv2.imshow(\"My Image\",img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss1mM5QWhvIk"
      },
      "source": [
        "# 3 Regiones de interés"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3HXsBhumTXu"
      },
      "source": [
        "Una **región de interés** (ROI) es una área específica dentro de imagen que se identifica con un propósito particular. Hay diversas formas de calcular ROIs utilizando OpenCV, pero vamos a ver las más intuitivas y simples.\n",
        "\n",
        "**El primero es definiendo o indexando un numpy array** como hemos visto anteriormente para crear una nueva imagen más específica. Vamos a suponer que estamos trabajando en un problema de reconocimiento de caras (por ejemplo, intentando reconocer ojos o algo similar). En vez de cargar la imagen entera, podemos simplemente cargar la parte de la imagen que nos interesa, lo que facilitaría el proceso de reconocimiento. \n",
        "\n",
        "Sabemos que los ojos están en la parte superior izquierda de la imagen, con lo que podemos crear una nueva imagen desde el píxel 50 al 180 en la vertical, y desde el 120 al 250 en la horizontal. Esto lo que hace es cropear la imagen. Esencialmente es una versión reducida de la imagen original:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s12oblGFmWs8"
      },
      "outputs": [],
      "source": [
        "#Cargamos una imagen\n",
        "img = cv2.imread(\"xiquet.jpg\")\n",
        "\n",
        "#ROI de la cara a partir de la posición de los píxeles\n",
        "face_ROI = img[50:180, 120:250]\n",
        "\n",
        "#Mostramos el ROI como una nueva imagen\n",
        "cv2.imshow(\"My Image\",face_ROI)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21F2BaEJ2jPo"
      },
      "source": [
        "**Otro método** que tenemos para crear una ROI es utilizando la función `selectROI`, lo que nos permite seleccionar un área con el ratón. Esta función devuelve 4 valores: las coordenadas x, y así como los píxeles de ancho y alto. Después, se utiliza el mismo método que antes para cropear la imagen utilizando la indexación de numpy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj7JD8LS2LrG"
      },
      "outputs": [],
      "source": [
        "#Cargamos una imagen\n",
        "img = cv2.imread(\"xiquet.jpg\")\n",
        "\n",
        "#ROI de la cara a partir de la selección con el ratón\n",
        "(x,y,w,h) = cv2.selectROI(\"My Image\", img) #coordenadas x, y así como píxeles de ancho y alto\n",
        "eyes_ROI = img[y:y+h, x:x+w]\n",
        "\n",
        "#Mostramos el ROI como una nueva imagen\n",
        "cv2.imshow(\"My Image\",eyes_ROI)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8I_ZBeS3GOm"
      },
      "source": [
        "En resumen, una ROI se usa para simplificar nuestras imágenes a regiones más pequeñas o específicas de las mismas. Esto son ejemplos simples pero podremos aplicarlos dependiendo del problema que queramos resolver. Ten en cuenta que si queremos realizar un problema de clasificación, el trabajar con ROIs simplica mucho el problema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuLEZOWMnq2A"
      },
      "source": [
        "# 4 Calculando similitud entre imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGOUuSQvnvx3"
      },
      "source": [
        "En este apartado vamos a trabajar sobre el concepto de comparación de imágenes. La comparación o similitud de imágenes hace referencia a alguna medida que nos permita establecer cómo de parecidas o diferentes son dos imágenes entre sí. \n",
        "\n",
        "Los humanos suelen ser bastante buenos identificando rápidamente la similitud entre dos imágenes. Sin embargo, implementar sistemas de este tipo en un programa puede ser una tarea compleja. Por ejemplo, fácilmente podrías establecer una comparación entre las siguientes imágenes, ¿cierto?\n",
        "\n",
        "<figure style=\"text-align:center\">\n",
        "  <center>\n",
        "  <img width = \"100%\" src=\"https://s3imagenes.s3-us-west-2.amazonaws.com/imagenes.png\"/>\n",
        "  <figcaption align=\"center\">Comparación de imágenes</figcaption>\n",
        "  </center>\n",
        "</figure>\n",
        "\n",
        "La comparación de imágenes es una tarea muy útil en aplicaciones como la detección de dinero falso, de tarjetas de crédito u obras de arte fraudulentas.\n",
        "\n",
        "En primer lugar, vamos a hablar de como podemos comparar dos imágenes por **diferencia de color** utilizando OpenCV. A continuación, puedes ver un ejemplo de cómo podemos utilizar esta técnica. En primer lugar, leemos dos imágenes para después aplicarle la función **substract** que recibe dos imágenes y calcula un array con la resta de los valores de los píxeles uno a uno. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR12_OcynBgI"
      },
      "source": [
        "## 4.1 Diferencia de color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wje-m2ILnxQw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#Cargamos las dos imágenes\n",
        "img1 = cv2.imread(\"xiquet.jpg\")\n",
        "img2 = cv2.imread(\"xiquet_rojo.jpg\")\n",
        "\n",
        "#Comparamos cada imagen con la original mediate subtract: sustrae cada píxel y valor de color\n",
        "diff_12 = cv2.subtract(img1,img2)\n",
        "\n",
        "#Sumamos todos los elementos del array diferencia para obtener un número representativo de cómo de similares o diferentes son\n",
        "print(np.sum(diff_12))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT8UenWGo7Bm"
      },
      "source": [
        "## 4.2 Ejercicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXwXwEKxo85l"
      },
      "source": [
        "3. Realiza un script llamado **ejercicio3** que complete el ejercicio anterior para comparar la imagen original con las otras 3 imágenes que se muestran más arriba. Muestra el resultado como un % de similitud. Para ello, puedes obtener la máxima diferencia posible como:\n",
        "\n",
        "$$num\\_pixels \\times 3 \\times 255$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flHKg_d6mQOb"
      },
      "source": [
        "Si has hecho el ejercicio anterior podrás ver que la imagen original comparada con la del perro tienen una similitud del 80%, algo que no parece lógico. Para entender esto, debemos comprender exactamente lo que está pasando. Lo que estamos comparando es el valor exacto de color de cada uno de los píxeles de ambas imágenes. Esto significa, por ejemplo, que si hay un perro blanco en el mismo sitio que un traje blanco, la diferencia de color será poca.\n",
        "\n",
        "Para verlo mejor, vamos a imprimir la diferencia entre la imagen \"xiquet.jpg\" y \"xiquet_rojo.jpg\", que son muy similares con un cuadro blanco:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViGZSfxdnPOh"
      },
      "outputs": [],
      "source": [
        "cv2.imshow(\"My Image\", diff_12)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdvC7xAjnVLw"
      },
      "source": [
        "Verás que sale una imagen completamente negra con un recuadro justo donde aparece el cuadro rojo. Esto significa que son la misma imagen excepto esta región, ya que cada pixel negro que ves indica que la diferencia de ese píxel en ambas imágenes es (0,0,0). Si cambias y comparas la imagen original con la del perro, verás lo que ocurre. \n",
        "\n",
        "La conclusión que puedes sacar de esta manera de comparar es que puedes utilizarla para comparar dos imágenes muy similares y saber si la diferencia es pequeña o no, pero si las imágenes son diferentes, no es muy útil porque mide cómo de parecido es el color de cada píxel dependiendo de su posición. Si tenemos un perro blanco y un traje blancoalum en la misma posición, la diferencia de color nos dirá que son similares."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i72CZRTEoIFr"
      },
      "source": [
        "## 4.3 Histogramas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbTjD3MErkic"
      },
      "source": [
        "Un histograma es una representación de la distribución de datos numéricos. Cuando vemos el histograma de una imagen, en la coordenada x aparece un valor de 0 a 255. Cada pixel tiene 3 valores, uno por cada color, por lo que puedo sacar un histograma por cada color individualmente, los tres valores sumados, en escala de grises o lo que sea mejor para nuestro sistema. Sabiendo que un valor BGR (0,0,0) es negro y (255,255,255) es blanco, podemos entender las barras verticales que vemos en el histograma.\n",
        "\n",
        "En definitiva, lo que nos muestra un histograma es el número de píxeles que tienen un determinado valor de color. Por tanto, no importa la posición ni la orientación de la imagen. \n",
        "\n",
        "A continuación podemos ver cómo podemos comparar histogramas usando OpenCV mediante la función **calcHist**. Cuando calculamos un histograma, después lo visualizamos con la función **savefig** para ver qué está pasando, por lo que es necesario importar **matplotlib**. Esta función es similar al show que utilizamos en el anterior colab, pero nos permite guardar la imagen cuando trabajamos por consola.\n",
        "\n",
        "Después, utilizamos la función **compareHist** que recibe dos histogramas y un método de comparación. En el ejemplo, utilizamos 0, que es el método de correlación. Una correlación de 0 significa que no hay similitud entre los histogramas (y por tanto, entre las imágenes), mientras que según se aproxima el valor a 1, significa que crece la similitud entre las imágenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJUOuqBwqAri"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#Cargamos las dos imágenes\n",
        "img1 = cv2.imread(\"xiquet.jpg\")\n",
        "img2 = cv2.imread(\"xiquet_rojo.jpg\")\n",
        "\n",
        "#Calculamos los histogramas \n",
        "#Entrada: image, channel, optional mask, histogram size, range of histogram\n",
        "#El canal [0] es el azul, pero podríamos hacerlo para los otros componentes\n",
        "img1_hist = cv2.calcHist([img1],[0],None,[256],[0,256])\n",
        "img2_hist = cv2.calcHist([img2],[0],None,[256],[0,256])\n",
        "\n",
        "#Dibujamos los histogramas para visualizarlos en la misma imagen\n",
        "plt.plot(img1_hist)\n",
        "plt.plot(img2_hist)\n",
        "plt.savefig(\"hist_comparison.png\")\n",
        "#plt.show()\n",
        "\n",
        "#Calculamos los valores de correlación\n",
        "img1_img2 = cv2.compareHist(img1_hist, img2_hist, 0)\n",
        "\n",
        "#Mostramos estos valores para ver las similitudes/diferencias \n",
        "print(img1_img2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBtxQXiGuEeg"
      },
      "source": [
        "La comparación de histogramas nos permite saber cómo de similares son dos o más histogramas. Entre dos imágenes que son iguales, sale un 1, lo cuál es lógico. Además, entre dos imágenes muy distintas, sale un valor muy pequeño, lo cual, también es lógico. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOUDFDMCwQSU"
      },
      "source": [
        "# 5 Identificando características comunes en una imagen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KeGClMkxgRk"
      },
      "source": [
        "En este apartado vamos a ver cómo podemos identificar características comunes en una imagen mediante OpenCV. Una característica (o feature) es cualquier información de una imagen que sea relevante para resolver una tarea relacionada con una aplicación concreta. \n",
        "\n",
        "Unas buenas características son los **bordes del objeto** que hay en la imagen. Si la imagen fuera un puzzle, posiblemente empezarías buscando las piezas que tienen el dibujo del borde, ya que será más fácil de montar que si empezamos por las piezas del fondo blanco. De la misma manera, un borde es una buena caracerística de una imagen porque es bastante fácil de distinguir de otras partes de la imagen.\n",
        "\n",
        "Otra buena característica son las **esquinas del objeto** de la imagen, porque también son fácilmente distinguibles de otras partes de la imagen. De hecho, es más fácil identificar una esquina que un borde. Por tanto, en muchos casos, las esquinas van a ser buenas características y son muy frecuentes en muchas aplicaciones.\n",
        "\n",
        "Ahora que ya sabemos lo que es una característica, vamos a centranos en el proceso de detección de características, que es un tema bastante común en procesamiento de imágenes y que consiste en encontrar o detectar características en una imagen. Hay muchos algoritmos que pueden usarse para feature detection como:\n",
        "\n",
        "* Harris corner detection\n",
        "* Shi-Tomasi corner detection\n",
        "* SURF\n",
        "* SLAM\n",
        "\n",
        "OpenCV tiene funciones para todos estos métodos y muchos más, dependiendo de lo que necesitemos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xS6HzBR-7VW"
      },
      "source": [
        "## 5.1 Detección de esquinas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbhWpzmKxemt"
      },
      "source": [
        "En esta sección vamos a implementar un sistema de detección de esquinas. En primer lugar, importamos los paquetes necesarios y cargamos la imagen.\n",
        "\n",
        "A continuación, convertimos esta imagen a escala de grises puesto que la función que vamos a utilizar requiere una imagen en escala de grises y en números en coma flotante. \n",
        "\n",
        "Después, utilizamos la función **cornerHarris** para detección de esquinas, donde el primer parámetro es la imagen, el segundo es el tamaño de bloque del vecindario, el tercer parámetro es el tamaño de K y el cuarto parámetro es el parámetro K. Puedes revisar la documentación de esta función:\n",
        "\n",
        "* https://docs.opencv.org/4.5.5/d4/d7d/tutorial_harris_detector.html\n",
        "\n",
        "Esta función devuelve un *response map* donde los valores más grandes corresponden a mayor probabilidad de esquinas.\n",
        "\n",
        "Sabiendo esto, podemos decirle que ponga un pixel rojo donde se detecten valores grandes, para de esta forma, visualmente podamos verlo de manera más clara. La respuesta a \"qué consideramos como un valor grande\" es algo que deberemos tunear, pero en este caso, diremos que es cualquier valor de max corner detection mayor que 0.01.\n",
        "\n",
        "La función de **dilate** es para dilatar los píxeles de las esquinas, ya que los píxeles individuales pueden ser difíciles de apreciar de manera visual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_czAkt0wT2U"
      },
      "outputs": [],
      "source": [
        "#Cargamos la imagen\n",
        "img = cv2.imread(\"laptop.jpg\")\n",
        "\n",
        "#Para la función cornerHarris(), la imagen de entrada debe estar en escala de grises y valores float32\n",
        "img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "img_gray = np.float32(img_gray)\n",
        "\n",
        "#Detectamos las esquinas utilizando la función cornerHarris() \n",
        "img_cornerdetect = cv2.cornerHarris(img_gray,2,3,0.04)\n",
        "\n",
        "#Dilatamos las esquinas para hacerlas más visibles \n",
        "img_cornerdetect = cv2.dilate(img_cornerdetect,None)\n",
        "\n",
        "#Donde haya un valor grande, ponemos un píxel rojo para mostrar las esquinas en la imagen original\n",
        "img[img_cornerdetect>0.01*img_cornerdetect.max()]=[0,0,255]\n",
        "\n",
        "cv2.imshow(\"My Image\",img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6Is_ELd---W"
      },
      "source": [
        "## 5.2 Detectando una plantilla (template matching)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAMBH0iuy-SA"
      },
      "source": [
        "A continuación vamos a ver un método para buscar y encontrar partes pequeñas en una gran imagen que se corresponden con una imagen plantilla. En primer lugar, descárgate la siguiente imagen: https://images3.alphacoders.com/674/thumb-1920-674893.jpg\n",
        "\n",
        "Tenemos también una imagen pequeña que es la plantilla, que en nuestro caso, es un pequeño recorte. El objetivo del template matching consiste en obtener dónde está la imagen pequeña en la imagen grande.\n",
        "\n",
        "A continuación puedes ver cómo lo podemos implementar en OpenCV. En primer lugar, cargamos las dos imágenes y después utilizamos la función **matchTemplate** donde el primer parámetro es la imagen original, el segundo parámetro es la plantilla y el tercer parámetro es el método de comparación de square difference (diferencia de cuadrados). Esta función lo que hace es ir pasando la plantilla en la imagen original y comparando las áreas que se sobreponen utilizando el método de square difference. Esto significa que si encuentra una área con un valor bajo de diferencia cuadrática, entonces esta área es muy parecida a la plantilla. Por tanto, llamamos a la función **minMaxLoc** que nos devuelve estos valores. De los valores devueltos, **min_loc** hace referencia a la esquina superior izquierda donde encuentra la plantilla.\n",
        "\n",
        "A continuación, queremos visualizar dónde hemos encontrado el mejor matching, para lo que básicamente dibujamos un rectángulo rojo a partir del punto donde ha encontrado el mínimo valor, con la función **rectangle** sobre la imagen original. Después, visualizamos esta imagen (original + rectángulo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ3-dU40zZyA"
      },
      "outputs": [],
      "source": [
        "#Load the original larger image and the template image\n",
        "img_original = cv2.imread(\"imagen1.jpg\")\n",
        "img_template = cv2.imread(\"plantilla.jpg\")\n",
        "\n",
        "#Apply template matching\n",
        "res = cv2.matchTemplate(img_original,img_template,0)\n",
        "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
        "\n",
        "print(\"imagen encontrada en \"+str(min_loc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsb84Iwm_Ryw"
      },
      "source": [
        "## 5.3 Ejercicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4eW0KPq_Qtb"
      },
      "source": [
        "4. Realiza un script llamado **ejercicio4* que complete el ejercicio anterior para dibujar un rectángulo azul en la imagen original en el punto exacto donde encuentre la plantilla y añade un texto que ponga \"marge\". Muestra la imagen resultante por pantalla."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "i72CZRTEoIFr",
        "E6Is_ELd---W"
      ],
      "name": "Usando OpenCV para trabajar con imágenes.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "fe91586cf7bfe2b2ebea6816f4bb33ddf372c0bc35522f95600b58b6b91f10f3"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
